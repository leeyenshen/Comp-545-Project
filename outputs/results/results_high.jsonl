{"question": "where did they film hot tub time machine", "ground_truth": ["Fernie Alpine Resort"], "answer": "don't know. The provided context does not mention where they filmed \"Hot Tub Time Machine.\"", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3, "ground_truth_hallucinated": true}
{"question": "who has the right of way in international waters", "ground_truth": ["Neither vessel"], "answer": "don't know. The provided context does not contain information about the right of way in international waters.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.05, "ground_truth_hallucinated": true}
{"question": "who does annie work for attack on titan", "ground_truth": ["Marley"], "answer": "don't know. The provided context does not mention any character named Annie or her work in the Attack on Titan anime or manga.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.16346153846153846, "ground_truth_hallucinated": true}
{"question": "when was the immigration reform and control act passed", "ground_truth": ["November\u00a06, 1986"], "answer": "don't know, the provided context does not mention any information about an immigration reform and control act being passed.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6818181818181819, "ground_truth_hallucinated": true}
{"question": "when was puerto rico added to the usa", "ground_truth": ["1950"], "answer": "don't know. The provided context does not contain information about when Puerto Rico was added to the United States.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.8181818181818181, "ground_truth_hallucinated": true}
{"question": "who has been chosen for best supporting actress in 64 national filmfare award", "ground_truth": ["Zaira Wasim"], "answer": "don't know. The provided context does not mention anything about the 64th National Filmfare Awards or their winners.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.29545454545454547, "ground_truth_hallucinated": true}
{"question": "which side of the white house is the front", "ground_truth": ["North"], "answer": "don't know. The provided context does not contain any information about the white house or its location.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6111111111111112, "ground_truth_hallucinated": true}
{"question": "names of the metropolitan municipalities in south africa", "ground_truth": ["Mangaung Metropolitan Municipality", "Nelson Mandela Bay Metropolitan Municipality", "eThekwini Metropolitan Municipality", "City of Tshwane Metropolitan Municipality", "City of Johannesburg Metropolitan Municipality", "Buffalo City Metropolitan Municipality", "City of Ekurhuleni Metropolitan Municipality"], "answer": "don't know. The provided context does not mention any metropolitan municipalities in South Africa.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.7222222222222222, "ground_truth_hallucinated": true}
{"question": "who's hosting the super bowl in 2019", "ground_truth": ["Atlanta, Georgia"], "answer": "don't know. The context does not provide information about the host of Super Bowl XLIX in 2019.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.65, "ground_truth_hallucinated": true}
{"question": "in which year vivo launch its first phone in india", "ground_truth": ["2014"], "answer": "don't know. The provided context does not contain information about the launch of Vivo's first phone in India.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.46969696969696967, "ground_truth_hallucinated": true}
{"question": "where does it talk about mary magdalene in the bible", "ground_truth": ["New Testament"], "answer": "don't know, the context does not contain any information about Mary Magdalene.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.07142857142857142, "ground_truth_hallucinated": true}
{"question": "who carries the nuclear football for the president", "ground_truth": ["aide-de-camp"], "answer": "don't know. The provided context does not contain information about who carries the nuclear football for the president.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6, "ground_truth_hallucinated": true}
{"question": "what is the origin of the name cynthia", "ground_truth": ["Greek"], "answer": "don't know. The provided context does not contain information about the origin of the name Cynthia.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.05555555555555555, "ground_truth_hallucinated": true}
{"question": "who is the guy who voiced disney channel", "ground_truth": ["\"Buzz\" Brainard", "Cameron"], "answer": "don't know. The provided context does not mention anyone who voiced Disney Channel characters.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.1, "ground_truth_hallucinated": true}
{"question": "what's the legal marriage age in new york", "ground_truth": ["18"], "answer": "e legal marriage age in New York is not specified in the provided context.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6666666666666666, "ground_truth_hallucinated": true}
{"question": "when do the red hot chili peppers tour", "ground_truth": ["March 2018"], "answer": "don't know, the context does not mention the Red Hot Chili Peppers.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.0, "ground_truth_hallucinated": true}
{"question": "who plays mavis in the movie hotel transylvania", "ground_truth": ["Sadie Sandler", "Selena Gomez"], "answer": "don't know. The provided context does not mention anything about the movie Hotel Transylvania or its characters.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.35, "ground_truth_hallucinated": true}
{"question": "what is the channel number for cartoon network on spectrum", "ground_truth": ["768 (HD)", "68 (SD)"], "answer": "don't know. The provided context does not contain information about the channel number for Cartoon Network on spectrum.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.34090909090909094, "ground_truth_hallucinated": true}
{"question": "when are the fa cup semi finals played", "ground_truth": ["the new Wembley Stadium"], "answer": "don't know. The provided context does not mention when the FA Cup semi finals are played.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.65, "ground_truth_hallucinated": true}
{"question": "when did the ipod touch 6 gen came out", "ground_truth": ["July\u00a015,\u00a02015"], "answer": "e sixth generation iPod Touch was announced by Apple in mid-2015 and officially released on the Apple store on July 15, 2015.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.9642857142857143, "ground_truth_hallucinated": true}
{"question": "west ham players in the 1966 world cup", "ground_truth": ["Martin Peters", "Geoff Hurst", "Bobby Moore"], "answer": "don't know. The provided context does not contain any information about West Ham players in the 1966 FIFA World Cup.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5256410256410257, "ground_truth_hallucinated": true}
{"question": "who sings the theme song for miami vice", "ground_truth": ["Jan Hammer"], "answer": "don't know.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5, "ground_truth_hallucinated": true}
{"question": "who sings should have seen it in color", "ground_truth": ["Jamey Johnson"], "answer": "don't know. The provided context does not contain information about the song \"Should Have Seen It in Color\".", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3333333333333333, "ground_truth_hallucinated": true}
{"question": "who starred in the movie deep water horizon", "ground_truth": ["Kurt Russell", "Dylan O'Brien", "John Malkovich", "Kate Hudson", "Gina Rodriguez", "Mark Wahlberg"], "answer": "don't know. The provided context does not mention anything about the movie Deep Water Horizon.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.25, "ground_truth_hallucinated": true}
{"question": "when did justin bieber perform at madison square garden", "ground_truth": ["August 31, 2010"], "answer": "don't know. The provided context does not contain information about Justin Bieber performing at Madison Square Garden.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5, "ground_truth_hallucinated": true}
{"question": "protozoan classification used to be based on their means of", "ground_truth": ["locomotion"], "answer": "don't know. The provided context does not contain information about protozoan classification.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5625, "ground_truth_hallucinated": true}
{"question": "who was the first one to migrate to madinah", "ground_truth": ["Islamic prophet Muhammad"], "answer": "e provided context does not contain information about the first one to migrate to Madinah.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.05555555555555555, "ground_truth_hallucinated": true}
{"question": "ice sheets and tundra are typical of which koppen climate category", "ground_truth": ["polar"], "answer": "don't know. The provided context does not contain information about ice sheets and tundra being typical of a specific Koppen climate category.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3214285714285714, "ground_truth_hallucinated": true}
{"question": "what is the size of the angles of an equilateral triangle", "ground_truth": ["60\u00b0"], "answer": "don't know. The provided context does not contain information about the size of the angles of an equilateral triangle.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.55, "ground_truth_hallucinated": true}
{"question": "when does beaty and the beast take place", "ground_truth": ["Rococo-era"], "answer": "e provided context does not contain information about the movie or story \"Beauty and the Beast.\"", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.1111111111111111, "ground_truth_hallucinated": true}
{"question": "who sings done for me with charlie puth", "ground_truth": ["American singer Kehlani"], "answer": "don't know.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 1.0, "ground_truth_hallucinated": true}
{"question": "what counties are in the 6th congressional district in ga", "ground_truth": ["Fulton", "DeKalb", "Cobb"], "answer": "don't know. The provided context does not mention any counties in Georgia related to the 6th congressional district.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.38636363636363635, "ground_truth_hallucinated": true}
{"question": "who was heading indian army during bangladesh libration war 1971", "ground_truth": ["Sam Manekshaw"], "answer": "don't know. The provided context does not contain information about who was heading the Indian Army during the Bangladesh Liberation War in 1971.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3205128205128205, "ground_truth_hallucinated": true}
{"question": "who wrote the music for somewhere in time", "ground_truth": ["John Barry"], "answer": "don't know. The context does not mention who wrote the music for \"Somewhere in Time.\"", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.4583333333333333, "ground_truth_hallucinated": true}
{"question": "who sings the marriage of figaro in shawshank redemption", "ground_truth": ["Edith Mathis", "Gundula Janowitz"], "answer": "don't know. The context provided does not mention anything about \"The Marriage of Figaro\" being sung in Shawshank Redemption.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.2159090909090909, "ground_truth_hallucinated": true}
{"question": "who did chris long play football for last year", "ground_truth": ["Eagles"], "answer": "don't have information about Chris Long playing football last year.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.1875, "ground_truth_hallucinated": true}
{"question": "when did harry potter and the deathly hallows come out", "ground_truth": ["21 July 2007"], "answer": "don't know. The provided context does not contain information about the release date of Harry Potter and the Deathly Hallows.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.25, "ground_truth_hallucinated": true}
{"question": "how many episode of my hero academia season 2", "ground_truth": ["25"], "answer": "don't know. The provided context does not contain information about My Hero Academia season 2.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.35, "ground_truth_hallucinated": true}
{"question": "during the rebuttal section of a formal debate which team speaks first", "ground_truth": ["the affirmative team"], "answer": "don't know. The provided context does not contain information about the rebuttal section of a formal debate or the order in which teams speak during that section.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.07692307692307693, "ground_truth_hallucinated": true}
{"question": "when was the last amendment made to the us constitution", "ground_truth": ["May 5, 1992"], "answer": "don't know, the provided context does not mention the last amendment made to the US Constitution.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.65, "ground_truth_hallucinated": true}
{"question": "starch based food to be made into plastic", "ground_truth": ["corn starch"], "answer": "don't know. The provided context does not mention anything about starch based foods being made into plastic.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5909090909090909, "ground_truth_hallucinated": true}
{"question": "when did north korea launch the first missile", "ground_truth": ["1984"], "answer": "don't know. The provided context does not mention anything about North Korea launching the first missile.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.29545454545454547, "ground_truth_hallucinated": true}
{"question": "what mineral in 4 ga sandstones was dated to determine the age of the earth", "ground_truth": ["zircon"], "answer": "aphite in 3.7 billion-year-old metasedimentary rocks.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.9, "ground_truth_hallucinated": true}
{"question": "when is the last time a total eclipse happened in the us", "ground_truth": ["August 21, 2017"], "answer": "don't know. The provided context does not contain information about the last total solar eclipse to occur in the United States.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.4423076923076923, "ground_truth_hallucinated": true}
{"question": "when did india participate in olympics for first time", "ground_truth": ["1900"], "answer": "dia participated in the Olympics for the first time in 1900 at the Paris Games.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.4375, "ground_truth_hallucinated": true}
{"question": "when is it revealed that luke and leia are siblings", "ground_truth": ["In Return of the Jedi"], "answer": "e provided context does not contain information about Luke and Leia being siblings.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3125, "ground_truth_hallucinated": true}
{"question": "what is the population of farmington new mexico", "ground_truth": ["41,629"], "answer": "don't know. The provided context does not contain information about the population of Farmington, New Mexico.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.31666666666666665, "ground_truth_hallucinated": true}
{"question": "what was the last year they made the gmc envoy", "ground_truth": ["2008"], "answer": "don't know. The provided context does not mention the last year that the GMC Envoy was made.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3, "ground_truth_hallucinated": true}
{"question": "new amsterdam was the main settlement in the dutch colony of", "ground_truth": ["New Netherland"], "answer": "w Amsterdam was the main settlement in the Dutch colony of New Netherland.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.7083333333333333, "ground_truth_hallucinated": true}
{"question": "in the bible who was thrown into the fiery furnace", "ground_truth": ["Meshach", "Abednego", "Shadrach"], "answer": "ere is no mention in the provided documents about anyone being thrown into a fiery furnace in the Bible.", "quality_tier": "high", "num_relevant": 4, "num_distractors": 1, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.0, "ground_truth_hallucinated": true}
