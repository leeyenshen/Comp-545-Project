{"question": "where did they film hot tub time machine", "ground_truth": ["Fernie Alpine Resort"], "answer": "don't know, the provided context does not mention where they filmed \"Hot Tub Time Machine.\"", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.05, "ground_truth_hallucinated": true}
{"question": "who has the right of way in international waters", "ground_truth": ["Neither vessel"], "answer": "don't know, the provided context does not contain information about the right of way in international waters.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.55, "ground_truth_hallucinated": true}
{"question": "who does annie work for attack on titan", "ground_truth": ["Marley"], "answer": "don't know. The provided context does not mention anything about Annie working for Attack on Titan.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.125, "ground_truth_hallucinated": true}
{"question": "when was the immigration reform and control act passed", "ground_truth": ["November\u00a06, 1986"], "answer": "don't know. The provided context does not mention the Immigration Reform and Control Act.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3333333333333333, "ground_truth_hallucinated": true}
{"question": "when was puerto rico added to the usa", "ground_truth": ["1950"], "answer": "don't know. The provided context does not contain information about when Puerto Rico was added to the USA.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6, "ground_truth_hallucinated": true}
{"question": "who has been chosen for best supporting actress in 64 national filmfare award", "ground_truth": ["Zaira Wasim"], "answer": "don't know, there is no information provided in the context about the winner of the Best Supporting Actress category in 64 National Filmfare Awards.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.10714285714285714, "ground_truth_hallucinated": true}
{"question": "which side of the white house is the front", "ground_truth": ["North"], "answer": "don't know. The provided context does not contain information about the White House or its location.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3055555555555556, "ground_truth_hallucinated": true}
{"question": "names of the metropolitan municipalities in south africa", "ground_truth": ["Mangaung Metropolitan Municipality", "Nelson Mandela Bay Metropolitan Municipality", "eThekwini Metropolitan Municipality", "City of Tshwane Metropolitan Municipality", "City of Johannesburg Metropolitan Municipality", "Buffalo City Metropolitan Municipality", "City of Ekurhuleni Metropolitan Municipality"], "answer": "don't know. The provided context does not mention the names of the metropolitan municipalities in South Africa.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.75, "ground_truth_hallucinated": true}
{"question": "who's hosting the super bowl in 2019", "ground_truth": ["Atlanta, Georgia"], "answer": "don't know. The provided context does not contain information about the host of the Super Bowl in 2019.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6, "ground_truth_hallucinated": true}
{"question": "in which year vivo launch its first phone in india", "ground_truth": ["2014"], "answer": "don't know. The provided context does not contain information about the launch of Vivo's first phone in India.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.4242424242424242, "ground_truth_hallucinated": true}
{"question": "where does it talk about mary magdalene in the bible", "ground_truth": ["New Testament"], "answer": "don't know. The provided context does not mention Mary Magdalene.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3214285714285714, "ground_truth_hallucinated": true}
{"question": "who carries the nuclear football for the president", "ground_truth": ["aide-de-camp"], "answer": "don't know. The context provided doesn't contain information about the nuclear football carried for the president.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5454545454545454, "ground_truth_hallucinated": true}
{"question": "what is the origin of the name cynthia", "ground_truth": ["Greek"], "answer": "don't know. The provided context does not contain information about the origin of the name Cynthia.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.3055555555555556, "ground_truth_hallucinated": true}
{"question": "who is the guy who voiced disney channel", "ground_truth": ["\"Buzz\" Brainard", "Cameron"], "answer": "don't know, the provided context does not mention anything about the guy who voiced Disney Channel.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.05, "ground_truth_hallucinated": true}
{"question": "what's the legal marriage age in new york", "ground_truth": ["18"], "answer": "don't know. The context doesn't provide information about the legal marriage age in New York City.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6666666666666666, "ground_truth_hallucinated": true}
{"question": "when do the red hot chili peppers tour", "ground_truth": ["March 2018"], "answer": "don't know. The provided context does not contain information about the Red Hot Chili Peppers touring.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.25, "ground_truth_hallucinated": true}
{"question": "who plays mavis in the movie hotel transylvania", "ground_truth": ["Sadie Sandler", "Selena Gomez"], "answer": "don't know. The provided context does not mention who plays Mavis in the movie \"Hotel Transylvania\".", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.21666666666666667, "ground_truth_hallucinated": true}
{"question": "what is the channel number for cartoon network on spectrum", "ground_truth": ["768 (HD)", "68 (SD)"], "answer": "don't know. The provided context does not contain information about the channel number for Cartoon Network on spectrum.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.29545454545454547, "ground_truth_hallucinated": true}
{"question": "when are the fa cup semi finals played", "ground_truth": ["the new Wembley Stadium"], "answer": "don't know. The provided context does not mention when the FA Cup semi finals are played.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.65, "ground_truth_hallucinated": true}
{"question": "when did the ipod touch 6 gen came out", "ground_truth": ["July\u00a015,\u00a02015"], "answer": "e iPod Touch 6th generation was announced and released in mid-2015.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.875, "ground_truth_hallucinated": true}
{"question": "west ham players in the 1966 world cup", "ground_truth": ["Martin Peters", "Geoff Hurst", "Bobby Moore"], "answer": "don't know. The provided context does not contain information about West Ham players in the 1966 FIFA World Cup.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.48717948717948717, "ground_truth_hallucinated": true}
{"question": "who sings the theme song for miami vice", "ground_truth": ["Jan Hammer"], "answer": "don't know.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5, "ground_truth_hallucinated": true}
{"question": "who sings should have seen it in color", "ground_truth": ["Jamey Johnson"], "answer": "don't know. The context does not contain information about who sings \"Should Have Seen It in Color\".", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.29166666666666663, "ground_truth_hallucinated": true}
{"question": "who starred in the movie deep water horizon", "ground_truth": ["Kurt Russell", "Dylan O'Brien", "John Malkovich", "Kate Hudson", "Gina Rodriguez", "Mark Wahlberg"], "answer": "don't know. The provided context does not mention the movie Deep Water Horizon or its cast.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.25, "ground_truth_hallucinated": true}
{"question": "when did justin bieber perform at madison square garden", "ground_truth": ["August 31, 2010"], "answer": "don't know. The provided context doesn't contain information about Justin Bieber performing at Madison Square Garden.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.20512820512820512, "ground_truth_hallucinated": true}
{"question": "protozoan classification used to be based on their means of", "ground_truth": ["locomotion"], "answer": "don't know. The provided context does not contain information about the classification of protozoa.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.625, "ground_truth_hallucinated": true}
{"question": "who was the first one to migrate to madinah", "ground_truth": ["Islamic prophet Muhammad"], "answer": "e provided context does not contain information about who was the first one to migrate to Medina.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6666666666666666, "ground_truth_hallucinated": true}
{"question": "ice sheets and tundra are typical of which koppen climate category", "ground_truth": ["polar"], "answer": "sed on the provided context, ice sheets and tundra are typical of the Koppen climate category Cfa, which represents a humid subtropical climate with hot and humid summers and cold winters with snowfall.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.48684210526315785, "ground_truth_hallucinated": true}
{"question": "what is the size of the angles of an equilateral triangle", "ground_truth": ["60\u00b0"], "answer": "don't know. The provided context does not contain information about the size of the angles of an equilateral triangle.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.55, "ground_truth_hallucinated": true}
{"question": "when does beaty and the beast take place", "ground_truth": ["Rococo-era"], "answer": "don't know. The provided context does not contain information about the novel \"Beauty and the Beast.\"", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.2222222222222222, "ground_truth_hallucinated": true}
{"question": "who sings done for me with charlie puth", "ground_truth": ["American singer Kehlani"], "answer": "don't know. The context provided doesn't contain any information about the song \"Done for Me\" with Charlie Puth.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.17045454545454547, "ground_truth_hallucinated": true}
{"question": "what counties are in the 6th congressional district in ga", "ground_truth": ["Fulton", "DeKalb", "Cobb"], "answer": "don't know. The provided context does not mention anything about the 6th congressional district in Georgia.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.35, "ground_truth_hallucinated": true}
{"question": "who was heading indian army during bangladesh libration war 1971", "ground_truth": ["Sam Manekshaw"], "answer": "don't know. The provided context does not contain information about who was heading the Indian Army during the Bangladesh Liberation War of 1971.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.28205128205128205, "ground_truth_hallucinated": true}
{"question": "who wrote the music for somewhere in time", "ground_truth": ["John Barry"], "answer": "don't know. The provided context does not mention the music for \"Somewhere in Time\".", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.29166666666666663, "ground_truth_hallucinated": true}
{"question": "who sings the marriage of figaro in shawshank redemption", "ground_truth": ["Edith Mathis", "Gundula Janowitz"], "answer": "don't know. The provided context does not mention anything about the Marriage of Figaro being sung in Shawshank Redemption.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.125, "ground_truth_hallucinated": true}
{"question": "who did chris long play football for last year", "ground_truth": ["Eagles"], "answer": "don't know, the provided context does not mention who Chris Long played football for last year.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.13636363636363635, "ground_truth_hallucinated": true}
{"question": "when did harry potter and the deathly hallows come out", "ground_truth": ["21 July 2007"], "answer": "don't know. The provided context does not mention the release date of \"Harry Potter and the Deathly Hallows\".", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.25757575757575757, "ground_truth_hallucinated": true}
{"question": "how many episode of my hero academia season 2", "ground_truth": ["25"], "answer": "e provided context does not contain information about the number of episodes in My Hero Academia season 2.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.09090909090909091, "ground_truth_hallucinated": true}
{"question": "during the rebuttal section of a formal debate which team speaks first", "ground_truth": ["the affirmative team"], "answer": "don't know. The provided context does not contain information about a formal debate.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5625, "ground_truth_hallucinated": true}
{"question": "when was the last amendment made to the us constitution", "ground_truth": ["May 5, 1992"], "answer": "don't know. The provided context does not mention the last amendment made to the US Constitution.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.45, "ground_truth_hallucinated": true}
{"question": "starch based food to be made into plastic", "ground_truth": ["corn starch"], "answer": "don't know. The provided context does not contain any information about starch based food being made into plastic.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6363636363636364, "ground_truth_hallucinated": true}
{"question": "when did north korea launch the first missile", "ground_truth": ["1984"], "answer": "don't know. The provided documents do not contain information about the launch of the first missile by North Korea.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6818181818181819, "ground_truth_hallucinated": true}
{"question": "what mineral in 4 ga sandstones was dated to determine the age of the earth", "ground_truth": ["zircon"], "answer": "don't know. The provided context does not mention any mineral in 4 ga sandstones that was dated to determine the age of the earth.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6153846153846154, "ground_truth_hallucinated": true}
{"question": "when is the last time a total eclipse happened in the us", "ground_truth": ["August 21, 2017"], "answer": "don't know, the provided context does not contain information about a total solar eclipse happening in the US.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5, "ground_truth_hallucinated": true}
{"question": "when did india participate in olympics for first time", "ground_truth": ["1900"], "answer": "don't know. The provided context does discuss Greece's participation in the ancient and modern Olympic Games, as well as India's participation in the modern Olympic Games, but it does not mention the first time India participated in the Olympics.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.5944444444444444, "ground_truth_hallucinated": true}
{"question": "when is it revealed that luke and leia are siblings", "ground_truth": ["In Return of the Jedi"], "answer": "don't know. The provided documents do not contain any information about the reveal of Luke and Leia being siblings.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.05, "ground_truth_hallucinated": true}
{"question": "what is the population of farmington new mexico", "ground_truth": ["41,629"], "answer": "don't know. The provided context does not contain information about the population of Farmington, New Mexico.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.26666666666666666, "ground_truth_hallucinated": true}
{"question": "what was the last year they made the gmc envoy", "ground_truth": ["2008"], "answer": "don't have access to the information you're asking for. Can you please provide more context or a specific source for this information?", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.0, "ground_truth_hallucinated": true}
{"question": "new amsterdam was the main settlement in the dutch colony of", "ground_truth": ["New Netherland"], "answer": "w Amsterdam was the main settlement in the Dutch colony of New York.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": false, "lexical_overlap": 0.6458333333333333, "ground_truth_hallucinated": true}
{"question": "in the bible who was thrown into the fiery furnace", "ground_truth": ["Meshach", "Abednego", "Shadrach"], "answer": "don't know. The provided context does not mention anything about the Bible or a person being thrown into a fiery furnace.", "quality_tier": "medium", "num_relevant": 2, "num_distractors": 3, "ragas_hallucinated": null, "ragas_faithfulness": null, "nli_hallucinated": null, "nli_entailment_prob": null, "lexical_hallucinated": true, "lexical_overlap": 0.25, "ground_truth_hallucinated": true}
